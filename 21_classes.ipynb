{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Libraries**"
      ],
      "metadata": {
        "id": "ODPjSqngi8WI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B_Q1OLuZi66o"
      },
      "outputs": [],
      "source": [
        "!pip install  sentencepiece -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "import gdown\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
        "from huggingface_hub import login\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import ast"
      ],
      "metadata": {
        "id": "x5EFJwTxjCSr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token = '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')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0AEAionjGfG",
        "outputId": "1291ccf2-c06d-406e-faca-6cea40ce52a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '12cSkbqONn4dTTqNtWJfV3QONZ_YL5Wfh'\n",
        "url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "gdown.download(url, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "HrrQqi-7jG6P",
        "outputId": "0d8a6d89-6a51-46e1-d24d-0f6ac73eb14b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=12cSkbqONn4dTTqNtWJfV3QONZ_YL5Wfh\n",
            "To: /content/full_okoz.json\n",
            "100%|██████████| 9.21M/9.21M [00:00<00:00, 26.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'full_okoz.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download_folder('https://drive.google.com/drive/folders/1dWP_krhq_jSZdxmYN4gCQXDpLfmAWN7l?usp=sharing', output='uzbek_xlm_roberta_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-1ab-22jRmv",
        "outputId": "72e5dd5e-d422-4f48-ef41-1d3f097bce39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1K6y8qGq-yPU32LeWhafyj9ZRmL3CeCGB config.json\n",
            "Processing file 1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU model.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K6y8qGq-yPU32LeWhafyj9ZRmL3CeCGB\n",
            "To: /content/uzbek_xlm_roberta_model/config.json\n",
            "100%|██████████| 709/709 [00:00<00:00, 1.88MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU\n",
            "From (redirected): https://drive.google.com/uc?id=1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU&confirm=t&uuid=27fb8990-2bf9-4878-8a17-40de0fd4beb1\n",
            "To: /content/uzbek_xlm_roberta_model/model.safetensors\n",
            "100%|██████████| 2.24G/2.24G [00:43<00:00, 51.1MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uzbek_xlm_roberta_model/config.json',\n",
              " 'uzbek_xlm_roberta_model/model.safetensors']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download_folder('https://drive.google.com/drive/folders/1UDLQbCEkdS5DWKokzl-NFqxHlBZ6MHK_?usp=sharing', output='uzbek_xlm_roberta_tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J93_GDPjsgM",
        "outputId": "6f847109-a8d5-4204-df0d-bd3b44d94df2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 10obthWQsAOOTtr8Qx7O_qaJhQkn-upVG sentencepiece.bpe.model\n",
            "Processing file 1Dao4duhJz3lGdjYMMTG1zztfXSJQWLPb special_tokens_map.json\n",
            "Processing file 1wzGPT51CaZGBmGbUIW54Jf7LV6MBe0Mr tokenizer_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10obthWQsAOOTtr8Qx7O_qaJhQkn-upVG\n",
            "To: /content/uzbek_xlm_roberta_tokenizer/sentencepiece.bpe.model\n",
            "100%|██████████| 5.07M/5.07M [00:00<00:00, 46.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Dao4duhJz3lGdjYMMTG1zztfXSJQWLPb\n",
            "To: /content/uzbek_xlm_roberta_tokenizer/special_tokens_map.json\n",
            "100%|██████████| 280/280 [00:00<00:00, 537kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wzGPT51CaZGBmGbUIW54Jf7LV6MBe0Mr\n",
            "To: /content/uzbek_xlm_roberta_tokenizer/tokenizer_config.json\n",
            "100%|██████████| 1.17k/1.17k [00:00<00:00, 1.85MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['uzbek_xlm_roberta_tokenizer/sentencepiece.bpe.model',\n",
              " 'uzbek_xlm_roberta_tokenizer/special_tokens_map.json',\n",
              " 'uzbek_xlm_roberta_tokenizer/tokenizer_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing for roberta**"
      ],
      "metadata": {
        "id": "bRbwrY1rjZJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"/content/uzbek_xlm_roberta_model\"\n",
        "tokenizer_dir = \"/content/uzbek_xlm_roberta_tokenizer\"\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(tokenizer_dir)\n",
        "model = XLMRobertaModel.from_pretrained(model_dir)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC3yXLtWjaeG",
        "outputId": "10dc2033-d92f-4cd0-8292-810d5c3d3504"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at /content/uzbek_xlm_roberta_model and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaModel(\n",
              "  (embeddings): XLMRobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): XLMRobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-23): 24 x XLMRobertaLayer(\n",
              "        (attention): XLMRobertaAttention(\n",
              "          (self): XLMRobertaSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): XLMRobertaSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): XLMRobertaIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): XLMRobertaOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): XLMRobertaPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing text**"
      ],
      "metadata": {
        "id": "0bIWlQiGj1fR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/full_okoz.json')"
      ],
      "metadata": {
        "id": "zXtInurWj293"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_remove = 'Hujjatga taklif yuborish Audioni tinglash'\n",
        "\n",
        "for i in range(len(df.related_texts)):\n",
        "    for j in range(len(df.related_texts[i])):\n",
        "        df.related_texts[i][j] = df.related_texts[i][j].replace(text_to_remove, \"\")"
      ],
      "metadata": {
        "id": "rUCYeOC_j4ez"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, model, tokenizer, device):\n",
        "    def filter_by_length(text_list):\n",
        "        return [text for text in text_list if len(text) > 4]\n",
        "\n",
        "    def process_okoz_text(text_list):\n",
        "        return [text.split('/')[0].strip() if '/' in text else text for text in text_list]\n",
        "\n",
        "    def has_minimum_elements(text_list, min_length=0):\n",
        "        return len(text_list) > min_length\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        text = text.lower()\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        return text\n",
        "\n",
        "    def remove_duplicates(text_list):\n",
        "        return list(set(text_list))\n",
        "\n",
        "    def remove_semicolons(text_list):\n",
        "        return [text.replace(';', '') for text in text_list]\n",
        "\n",
        "    def clean_individual_text(text):\n",
        "        text = text.lower()\n",
        "        text = text.replace('‘', \"'\").replace('’', \"'\").replace('`', \"'\")\n",
        "        text = re.sub(r'[^a-z\\.\\'\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def embed_document(df, model, tokenizer, device):\n",
        "        embeddings_list = []\n",
        "\n",
        "        for i in range(len(df['related_texts'])):\n",
        "            cleaned_text = clean_individual_text(df['related_texts'][i])\n",
        "\n",
        "            inputs = tokenizer(cleaned_text, return_tensors='pt', truncation=True, padding=True)\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            embeddings = outputs.last_hidden_state\n",
        "            doc_embedding = torch.mean(embeddings, dim=1).squeeze()\n",
        "\n",
        "            embeddings_list.append(doc_embedding.cpu().numpy())\n",
        "\n",
        "        df['embeddings'] = embeddings_list\n",
        "\n",
        "        return df\n",
        "\n",
        "    df.loc[:, 'okoz_text'] = df['okoz_text'].apply(filter_by_length)\n",
        "    df.loc[:, 'okoz_text'] = df['okoz_text'].apply(process_okoz_text)\n",
        "    df = df[df['okoz_text'].apply(lambda x: has_minimum_elements(x))]\n",
        "    df.loc[:, 'okoz_text'] = df['okoz_text'].apply(remove_duplicates)\n",
        "    df.loc[:, 'okoz_text'] = df['okoz_text'].apply(remove_semicolons)\n",
        "    df = df[df['okoz_text'].apply(len) == 1]\n",
        "    df = df.reset_index(drop=True)\n",
        "    df.loc[:, 'okoz_text'] = df['okoz_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    df['related_texts'] = df['related_texts'].apply(lambda x: ' '.join(x))\n",
        "    df['related_texts'] = df['related_texts'].apply(clean_individual_text)\n",
        "\n",
        "    class_counts = df['okoz_text'].value_counts()\n",
        "\n",
        "    label_to_numeric = {}\n",
        "    label_counter = 1\n",
        "\n",
        "    for label, count in class_counts.items():\n",
        "        if count < 40:\n",
        "            label_to_numeric[label] = 0\n",
        "        else:\n",
        "            label_to_numeric[label] = label_counter\n",
        "            label_counter += 1\n",
        "\n",
        "    df.loc[:, 'label'] = df['okoz_text'].map(label_to_numeric)\n",
        "\n",
        "    df = embed_document(df, model, tokenizer, device)\n",
        "\n",
        "    columns_to_drop = ['okoz_text']\n",
        "    df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "    return df, label_to_numeric\n",
        "\n",
        "df, label_to_numeric = preprocess_data(df, model, tokenizer, device)"
      ],
      "metadata": {
        "id": "O79lqZvcj90U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_model(df, batch_size):\n",
        "    X = np.array(df['embeddings'].tolist())\n",
        "    y = np.array(df['label'])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "\n",
        "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "train_loader, test_loader = prep_model(df, 32)"
      ],
      "metadata": {
        "id": "i6pgSI-BlFvK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_numeric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id3vcQXqlGmO",
        "outputId": "af70237b-f8af-4e75-876d-e002483a343d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'01.00.00.00 Konstitutsiyaviy tuzum': 1,\n",
              " '04.00.00.00 Oila qonunchiligi': 2,\n",
              " '16.00.00.00 Xavfsizlik va huquq tartibot muhofazasi': 3,\n",
              " '17.00.00.00 Odil sudlov': 4,\n",
              " '02.00.00.00 Davlat boshqaruvi asoslari': 5,\n",
              " '03.00.00.00 Fuqarolik qonunchiligi': 6,\n",
              " '18.00.00.00 Prokuratura. Advokatura. Notariat. Yuridik xizmat. Adliya organlari. FHDY organlari': 7,\n",
              " '19.00.00.00 Xalqaro munosabatlar. Xalqaro huquq': 8,\n",
              " '06.00.00.00 Ijtimoiy ta’minot va ijtimoiy sug‘urta to‘g‘risidagi qonunchilik. Ijtimoiy himoya': 9,\n",
              " '07.00.00.00 Moliya va kredit to‘g‘risidagi qonunchilik. Bank faoliyati': 10,\n",
              " '09.00.00.00 Tadbirkorlik va xo‘jalik faoliyati': 11,\n",
              " '14.00.00.00 Sog‘liqni saqlash. Jismoniy tarbiya. Sport. Turizm': 12,\n",
              " '05.00.00.00 Mehnat va aholining bandligi to‘g‘risidagi qonunchilik': 13,\n",
              " '13.00.00.00 Ta’lim. Fan. Madaniyat': 14,\n",
              " '08.00.00.00 Uy-joy qonunchiligi. Kommunal xo‘jalik': 0,\n",
              " '11.00.00.00 Atrof tabiiy muhit va tabiiy resurslar': 0,\n",
              " '15.00.00.00 Mudofaa': 0,\n",
              " '12.00.00.00 Axborot va axborotlashtirish': 0,\n",
              " '21.00.00.00 O‘zgartirish va qo‘shimchalar kiritish bo‘yicha kompleks tusdagi hujjatlar': 0,\n",
              " '20.00.00.00 Kadrlar masalalari, mukofotlar, faxriy unvonlar, esdalik nishonlar, faxriy yorliqlar bilan taqdirlash, amnistiya va afv etish masalalari hamda fuqarolik berish bo‘yicha individual aktlar': 0,\n",
              " '10.00.00.00 Tashqi iqtisodiy faoliyat. Bojxona ishi': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 6\n",
        "input_dim = np.array(df['embeddings'][0]).shape[0]"
      ],
      "metadata": {
        "id": "mRHtZUTVlL_u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, model, criterion, optimizer, scheduler, num_epochs=100):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        scheduler.step(epoch_loss)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "    print(\"Training Complete\")"
      ],
      "metadata": {
        "id": "jDN-ZNe3mt6E"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, criterion, df):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0.0\n",
        "    incorrect_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            incorrect_indices = (predicted != labels).nonzero(as_tuple=True)[0]\n",
        "            for idx in incorrect_indices:\n",
        "                original_idx = i * test_loader.batch_size + idx.item()\n",
        "                text = df.iloc[original_idx]['related_texts']\n",
        "                true_label = labels[idx].item()\n",
        "                predicted_label = predicted[idx].item()\n",
        "                incorrect_predictions.append((text, true_label, predicted_label))\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = total_loss / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%, Test Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    if incorrect_predictions:\n",
        "        print(\"\\nIncorrect Predictions:\")\n",
        "        for text, true_label, predicted_label in incorrect_predictions:\n",
        "            print(f\"Text: {text}\")\n",
        "            print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\\n\")\n",
        "\n",
        "    return accuracy, avg_loss, incorrect_predictions"
      ],
      "metadata": {
        "id": "tQXUPSM3mvsR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MulticlassModel1(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MulticlassModel1, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 512)\n",
        "        self.layer2 = nn.Linear(512, 1024)\n",
        "        self.layer3 = nn.Linear(1024, 512)\n",
        "        self.output = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(1024)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.layer1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.batch_norm2(self.layer2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5lIAyqAEmx9U"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MulticlassModel1(input_size=input_dim, num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
      ],
      "metadata": {
        "id": "suQFXL9gmzdA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "# Setting CUDA_LAUNCH_BLOCKING to 1 forces CUDA operations to be synchronous, making it easier to pinpoint the exact location of the error.\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "# This ensures that CUDA operations are synchronous and errors are reported immediately."
      ],
      "metadata": {
        "id": "0iAoc33Om_id"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n",
        "accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "VSF4EAAlm0w7",
        "outputId": "8f203315-c06b-46cd-8bdc-bf4c2772e41c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-88117be8682d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-6fefaf20aa18>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ]
}