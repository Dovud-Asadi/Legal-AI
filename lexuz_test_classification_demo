{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Data Preparation**"],"metadata":{"id":"LcK6YjCBxJra"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VxFVGaYtR0g","outputId":"a9a93430-d4b4-4e80-9556-ee42e1b137d4","executionInfo":{"status":"ok","timestamp":1726209414034,"user_tz":-300,"elapsed":15721,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install transformers wandb gensim sentencepiece -q"]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","import string\n","import re\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from transformers import XLMRobertaTokenizer, XLMRobertaModel\n","import torch.nn as nn\n","from torch.cuda.amp import autocast\n","import multiprocessing\n","from gensim.models import Word2Vec\n","import wandb\n","from google.colab import userdata\n","import gdown"],"metadata":{"id":"Q1LfpDzatWvp","executionInfo":{"status":"ok","timestamp":1726209433051,"user_tz":-300,"elapsed":19022,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["file_id = '1LoIkGczZJZVTz88_xJg3aBDWpALEqGla'\n","url = f'https://drive.google.com/uc?export=download&id={file_id}'\n","\n","gdown.download(url, quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"dnvr5c7cthSC","outputId":"da10a867-ac5e-4343-b21f-83e6cabee622","executionInfo":{"status":"ok","timestamp":1726209444227,"user_tz":-300,"elapsed":11179,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?export=download&id=1LoIkGczZJZVTz88_xJg3aBDWpALEqGla\n","From (redirected): https://drive.google.com/uc?export=download&id=1LoIkGczZJZVTz88_xJg3aBDWpALEqGla&confirm=t&uuid=993236c9-e439-47b5-81b0-e599c4660555\n","To: /content/umid.json\n","100%|██████████| 381M/381M [00:07<00:00, 51.7MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'umid.json'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["gdown.download_folder('https://drive.google.com/drive/folders/1dWP_krhq_jSZdxmYN4gCQXDpLfmAWN7l?usp=sharing', output='uzbek_xlm_roberta_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySM2Do5rtiqA","outputId":"66855be5-9896-4e15-fad0-27a28eeb7b3f","executionInfo":{"status":"ok","timestamp":1726209499818,"user_tz":-300,"elapsed":55598,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Retrieving folder contents\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 1K6y8qGq-yPU32LeWhafyj9ZRmL3CeCGB config.json\n","Processing file 1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU model.safetensors\n"]},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents completed\n","Building directory structure\n","Building directory structure completed\n","Downloading...\n","From: https://drive.google.com/uc?id=1K6y8qGq-yPU32LeWhafyj9ZRmL3CeCGB\n","To: /content/uzbek_xlm_roberta_model/config.json\n","100%|██████████| 709/709 [00:00<00:00, 2.27MB/s]\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU\n","From (redirected): https://drive.google.com/uc?id=1v62TaVs1gWlWuyFYAC9k0QXdJq3mh-KU&confirm=t&uuid=93f3a0a7-2675-47b8-b281-861d321c1f71\n","To: /content/uzbek_xlm_roberta_model/model.safetensors\n","100%|██████████| 2.24G/2.24G [00:47<00:00, 47.5MB/s]\n","Download completed\n"]},{"output_type":"execute_result","data":{"text/plain":["['uzbek_xlm_roberta_model/config.json',\n"," 'uzbek_xlm_roberta_model/model.safetensors']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["gdown.download_folder('https://drive.google.com/drive/folders/1UDLQbCEkdS5DWKokzl-NFqxHlBZ6MHK_?usp=sharing', output='uzbek_xlm_roberta_tokenizer')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSye0dWqtjxk","outputId":"c7c94d28-2754-4741-8caf-8b895bcffe62","executionInfo":{"status":"ok","timestamp":1726209512879,"user_tz":-300,"elapsed":13066,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Retrieving folder contents\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 10obthWQsAOOTtr8Qx7O_qaJhQkn-upVG sentencepiece.bpe.model\n","Processing file 1Dao4duhJz3lGdjYMMTG1zztfXSJQWLPb special_tokens_map.json\n","Processing file 1wzGPT51CaZGBmGbUIW54Jf7LV6MBe0Mr tokenizer_config.json\n"]},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents completed\n","Building directory structure\n","Building directory structure completed\n","Downloading...\n","From: https://drive.google.com/uc?id=10obthWQsAOOTtr8Qx7O_qaJhQkn-upVG\n","To: /content/uzbek_xlm_roberta_tokenizer/sentencepiece.bpe.model\n","100%|██████████| 5.07M/5.07M [00:00<00:00, 31.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Dao4duhJz3lGdjYMMTG1zztfXSJQWLPb\n","To: /content/uzbek_xlm_roberta_tokenizer/special_tokens_map.json\n","100%|██████████| 280/280 [00:00<00:00, 1.06MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1wzGPT51CaZGBmGbUIW54Jf7LV6MBe0Mr\n","To: /content/uzbek_xlm_roberta_tokenizer/tokenizer_config.json\n","100%|██████████| 1.17k/1.17k [00:00<00:00, 4.10MB/s]\n","Download completed\n"]},{"output_type":"execute_result","data":{"text/plain":["['uzbek_xlm_roberta_tokenizer/sentencepiece.bpe.model',\n"," 'uzbek_xlm_roberta_tokenizer/special_tokens_map.json',\n"," 'uzbek_xlm_roberta_tokenizer/tokenizer_config.json']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["model_dir = \"/content/uzbek_xlm_roberta_model\"\n","tokenizer_dir = \"/content/uzbek_xlm_roberta_tokenizer\"\n","\n","tokenizer = XLMRobertaTokenizer.from_pretrained(tokenizer_dir)\n","model_embedding = XLMRobertaModel.from_pretrained(model_dir).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","model_embedding.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_BjKsT9tlA5","outputId":"74a9daec-e2b8-44ec-c168-73fe4c5a8223","executionInfo":{"status":"ok","timestamp":1726209517509,"user_tz":-300,"elapsed":4024,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaModel were not initialized from the model checkpoint at /content/uzbek_xlm_roberta_model and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["XLMRobertaModel(\n","  (embeddings): XLMRobertaEmbeddings(\n","    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n","    (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","    (token_type_embeddings): Embedding(1, 1024)\n","    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): XLMRobertaEncoder(\n","    (layer): ModuleList(\n","      (0-23): 24 x XLMRobertaLayer(\n","        (attention): XLMRobertaAttention(\n","          (self): XLMRobertaSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): XLMRobertaSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): XLMRobertaIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): XLMRobertaOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): XLMRobertaPooler(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Load dataset\n","df_roberta = pd.read_json('umid.json')"],"metadata":{"id":"nzMMJ-K2toAu","executionInfo":{"status":"ok","timestamp":1726209525297,"user_tz":-300,"elapsed":7790,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Remove unnecessary text in all rows\n","df_roberta['related_texts'] = df_roberta['related_texts'].apply(lambda texts: [t.replace('Hujjatga taklif yuborish Audioni tinglash', \"\") for t in texts])"],"metadata":{"id":"m0ekNtEWtpyX","executionInfo":{"status":"ok","timestamp":1726209527132,"user_tz":-300,"elapsed":1837,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def preprocess_okoz(df, number):\n","    \"\"\"\n","    Function to preprocess 'okoz_text' in a dataframe based on a specified number.\n","    \"\"\"\n","    # Check if 'okoz_text' contains the number followed by \".0\"\n","    def contains_number_point_zero(okoz_list):\n","        return any(f'{number}.0' in item for item in okoz_list)\n","\n","    # Filter by length, keep elements starting with number, and process text\n","    def process_okoz_text(text_list):\n","        filtered = [text for text in text_list if len(text) > 4 and text.startswith(f'{number}')]\n","        processed = [text.split('/')[1].strip() if '/' in text else text for text in filtered]\n","        return processed\n","\n","    # General text preprocessing\n","    def preprocess_text(text):\n","        text = text.lower().translate(str.maketrans('', '', string.punctuation))\n","        return text\n","\n","    # Remove duplicates and semicolons\n","    def clean_text(text_list):\n","        cleaned = list(set(text_list))\n","        return [text.replace(';', '') for text in cleaned]\n","\n","    # Apply the filter and preprocessing functions\n","    df_filtered = df[df['okoz_text'].apply(contains_number_point_zero)].copy()  # Always use .copy() to avoid warnings\n","    df_filtered.loc[:, 'okoz_text'] = df_filtered['okoz_text'].apply(process_okoz_text)  # Use .loc to modify\n","    df_filtered = df_filtered[df_filtered['okoz_text'].apply(lambda x: len(x) > 0)].copy()  # Re-filter, then .copy()\n","    df_filtered.loc[:, 'okoz_text'] = df_filtered['okoz_text'].apply(clean_text)  # Use .loc for assignment\n","    df_filtered = df_filtered[df_filtered['okoz_text'].apply(len) == 1].copy()  # Keep rows where list has exactly 1 element\n","    df_filtered.loc[:, 'okoz_text'] = df_filtered['okoz_text'].apply(lambda x: ' '.join(x).replace(\"]\", \"\"))   # Flatten the list to a string\n","    df_filtered = df_filtered.reset_index(drop=True)\n","\n","    return df_filtered"],"metadata":{"id":"bjAjezl7tutI","executionInfo":{"status":"ok","timestamp":1726209775496,"user_tz":-300,"elapsed":417,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["df_04  = preprocess_okoz(df_roberta, \"04\")"],"metadata":{"id":"G_SXqrkJGyUS","executionInfo":{"status":"ok","timestamp":1726209776406,"user_tz":-300,"elapsed":387,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Kyk5P0O7N13b"}},{"cell_type":"code","source":["df_04.okoz_text.value_counts(sort=df_04['okoz_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"swYbB5W3HAVo","executionInfo":{"status":"error","timestamp":1726210164753,"user_tz":-300,"elapsed":379,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"e35f9313-1b66-414f-f1b4-687b74b99077"},"execution_count":32,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-b446e0f3bb60>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_04\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mokoz_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_04\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'okoz_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \"\"\"\n\u001b[0;32m-> 1010\u001b[0;31m         return algorithms.value_counts_internal(\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mvalue_counts_internal\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1520\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."]}]},{"cell_type":"code","source":["# prompt: sort df_04.okoz_text.value_counts alphabetically\n","\n","sorted_counts = df_04.okoz_text.value_counts().sort_index()\n","print(sorted_counts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqO_wuhnJPb9","executionInfo":{"status":"ok","timestamp":1726210198959,"user_tz":-300,"elapsed":470,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"cc1c5c6f-84b6-4530-c383-7e3ff311e0dc"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["okoz_text\n","04.01.00.00 Umumiy qoidalar                                                                                                33\n","04.02.00.00 Nikoh                                                                                                          54\n","04.03.00.00 Bolalarning kelib chiqishini belgilash                                                                          2\n","04.04.00.00 Ota-onalar va bolalarning hamda boshqa shaxslarning huquq va majburiyatlari. Aliment majburiyatlari            29\n","04.05.00.00 Ota-onalar qarovisiz qolgan bolalarni tarbiyalash shakllari                                                   113\n","04.06.00.00 Fuqarolik holati dalolatnomalarini qayd qilish (shuningdek, 03.02.08.00ga qarang)                             252\n","04.07.00.00 Familiya, ism va ota ismini o‘zgartirish                                                                        3\n","04.08.00.00 Oila, onalik, otalik va bolalikni himoya qilish va ijtimoiy qo‘llab-quvvatlash                                 99\n","04.09.00.00 Chet ellik fuqarolar va fuqaroligi bo‘lmagan shaxslar ishtirokidagi oilaviy munosabatlarni tartibga solish      2\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["def preprocess_all_numbers(df, start=1, end=21):\n","    \"\"\"\n","    Function to preprocess the dataframe for all numbers from start to end.\n","    Concatenates results into one DataFrame.\n","    \"\"\"\n","    numbers = [f'{i:02}' for i in range(start, end + 1)]\n","    df_list = [preprocess_okoz(df, number) for number in numbers]\n","\n","    # Concatenate all processed DataFrames\n","    df_all = pd.concat(df_list, ignore_index=True)\n","\n","    return df_all"],"metadata":{"id":"lSklh0BetyIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_all = preprocess_all_numbers(df_roberta)"],"metadata":{"id":"TLex5TnWtzSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(df):\n","    \"\"\"\n","    Preprocesses the 'related_texts' column in the DataFrame by cleaning and standardizing the text.\n","    \"\"\"\n","\n","    def clean_individual_text(text):\n","        # Lowercase the text and replace curly quotes/backticks with standard single quotes\n","        text = text.lower()\n","        text = text.replace('‘', \"'\").replace('’', \"'\").replace('`', \"'\")\n","\n","        # Remove all non-alphabetical characters except periods, single quotes, and spaces\n","        text = re.sub(r'[^a-z\\.\\'\\s]', '', text)\n","\n","        # Replace multiple spaces with a single space and strip leading/trailing spaces\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","\n","        return text\n","\n","    # Join list of texts into a single string, then apply the cleaning function\n","    df.loc[:, 'related_texts'] = df['related_texts'].apply(lambda x: ' '.join(x))  # Use .loc to avoid the warning\n","    df.loc[:, 'related_texts'] = df['related_texts'].apply(clean_individual_text)  # Apply cleaning function\n","\n","    return df"],"metadata":{"id":"fM6xqCnmt0Vk","executionInfo":{"status":"ok","timestamp":1726209814245,"user_tz":-300,"elapsed":401,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["df_new = preprocess_text(df_04)"],"metadata":{"id":"_SzyPSCYt2JK","executionInfo":{"status":"ok","timestamp":1726209836807,"user_tz":-300,"elapsed":979,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["df_new.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhsEIVnduRKV","outputId":"5b663954-763d-4749-f52a-4683ac2cd451","executionInfo":{"status":"ok","timestamp":1726209839376,"user_tz":-300,"elapsed":368,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 587 entries, 0 to 586\n","Data columns (total 2 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   okoz_text      587 non-null    object\n"," 1   related_texts  587 non-null    object\n","dtypes: object(2)\n","memory usage: 9.3+ KB\n"]}]},{"cell_type":"markdown","source":["# **Roberta Embedding**"],"metadata":{"id":"f36u6lDaxOcj"}},{"cell_type":"code","source":["def preprocess_data_embedd(df, model, tokenizer, device, batch_size=64, max_length=256):\n","    # Clean texts without adding a new column\n","    df['related_texts'] = df['related_texts'].fillna('')  # Ensure no NaN values\n","\n","    # Function to embed the document\n","    def embed_document(df, model, tokenizer, device, batch_size=64, max_length=256):\n","        texts = df['related_texts'].tolist()\n","\n","        # Tokenize texts and prepare DataLoader\n","        inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n","        dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","        dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=True, num_workers=2)\n","\n","        embeddings_list = []\n","        model.to(device)\n","        for batch in dataloader:\n","            input_ids, attention_mask = [t.to(device, non_blocking=True) for t in batch]\n","            with torch.amp.autocast(device_type='cuda'):  # Mixed precision for efficiency\n","                with torch.no_grad():\n","                    outputs = model(input_ids, attention_mask=attention_mask)\n","                    embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n","            embeddings_list.extend(embeddings.cpu().numpy())  # Move to CPU memory to free GPU memory\n","\n","        df['embeddings'] = embeddings_list\n","        return df\n","\n","        # Assign label 1 to \"04.01.00.00 Umumiy qoidalar\" and 0 to others\n","    df['label'] = (df['okoz_text'] == '04.01.00.00 Umumiy qoidalar').astype(int)\n","\n","    # Embed document\n","    df = embed_document(df, model, tokenizer, device, batch_size, max_length)\n","\n","    # Drop the unnecessary column\n","    df = df.drop(columns=['okoz_text'])\n","\n","    # Print GPU memory usage stats\n","    print(f\"Memory allocated: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB\")\n","    print(f\"Memory reserved: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB\")\n","\n","    return df"],"metadata":{"id":"oCHUAtL1t503","executionInfo":{"status":"ok","timestamp":1726210002317,"user_tz":-300,"elapsed":393,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u47T_bMsuo7J","outputId":"2acb1297-2265-4473-eece-bc567f4d3560","executionInfo":{"status":"ok","timestamp":1726209973368,"user_tz":-300,"elapsed":451,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["df_embed = preprocess_data_embedd(df_new, model_embedding, tokenizer, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7PzPvt8ussQ","outputId":"828cfa98-e2fa-4043-a7f3-3244f25d8bfd","executionInfo":{"status":"ok","timestamp":1726210025170,"user_tz":-300,"elapsed":16096,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory allocated: 2.09 GB\n","Memory reserved: 3.91 GB\n"]}]},{"cell_type":"code","source":["df_embed.label.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"9Swa-AqrIr7v","executionInfo":{"status":"ok","timestamp":1726211901271,"user_tz":-300,"elapsed":502,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"726aa93a-31fd-48db-e2e5-1d8ae1177fce"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["label\n","0    55\n","1    33\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["# prompt: only take 10 percent of label 0\n","\n","import pandas as pd\n","# Separate the DataFrame based on label\n","df_label_0 = df_embed[df_embed['label'] == 0]\n","df_label_1 = df_embed[df_embed['label'] == 1]\n","\n","# Sample 10% of label 0 data\n","df_label_0_sampled = df_label_0.sample(frac=0.1, random_state=42)\n","\n","# Concatenate the sampled label 0 data with label 1 data\n","df_embed = pd.concat([df_label_0_sampled, df_label_1], ignore_index=True)\n"],"metadata":{"id":"PehV3UFtPpt1","executionInfo":{"status":"ok","timestamp":1726211897243,"user_tz":-300,"elapsed":377,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["df_embed.to_csv('roberta_embedded_with_text.csv', index=False)\n","df_embed.to_json('roberta_embedded_with_texts.json', index=False)\n","\n","!cp \"/content/roberta_embedded_with_text.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Roberta_Uzbek/Embedded Data\"\n","!cp \"/content/roberta_embedded_with_texts.json\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Roberta_Uzbek/Embedded Data\""],"metadata":{"id":"Bd_nahehIYyk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_embeded = df_embed[['embeddings', 'label']]"],"metadata":{"id":"Ufz_H_ukHUNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_embeded.to_csv('roberta_embedded.csv', index=False)\n","df_embeded.to_json('roberta_embedding.json', index=False)\n","\n","!cp \"/content/roberta_embedded.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Roberta_Uzbek/Embedded Data\"\n","!cp \"/content/roberta_embedding.json\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Roberta_Uzbek/Embedded Data\""],"metadata":{"id":"G055GNelHcwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_df = pd.DataFrame(list(label_to_numeric.items()), columns=['okoz_text', 'label'])"],"metadata":{"id":"7HwzXYnYEx4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_df.to_csv('label_to_numeric.csv', index=False)\n","\n","!cp \"/content/label_to_numeric.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Roberta_Uzbek\""],"metadata":{"id":"Btu-XFt8Ezdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prep_model(df, batch_size):\n","    X = np.array(df['embeddings'].tolist())\n","    y = np.array(df['label'])\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n","    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader"],"metadata":{"id":"tS5TPLLvvcEu","executionInfo":{"status":"ok","timestamp":1726211906504,"user_tz":-300,"elapsed":479,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["train_loader, test_loader = prep_model(df_embed, 32)"],"metadata":{"id":"oniWtJxCwu4x","executionInfo":{"status":"ok","timestamp":1726211909335,"user_tz":-300,"elapsed":393,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_classes = df_embed['label'].nunique()\n","input_dim = np.array(df_embed['embeddings'][0]).shape[0]"],"metadata":{"id":"24lycyBCwxIG","executionInfo":{"status":"ok","timestamp":1726210423315,"user_tz":-300,"elapsed":405,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def train_model(train_loader, model, criterion, optimizer, scheduler, num_epochs=100):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            # Convert labels to float\n","            labels = labels.unsqueeze(1).float() # Ensure labels are float and have shape [batch_size, 1]\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        scheduler.step(epoch_loss)\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n","\n","    print(\"Training Complete\")"],"metadata":{"id":"Q060iwRpw0t5","executionInfo":{"status":"ok","timestamp":1726210947174,"user_tz":-300,"elapsed":406,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"yGUo2THAOhWc"}},{"cell_type":"code","source":["def train_model(train_loader, model, criterion, optimizer, scheduler, num_epochs=100):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.unsqueeze(1).float())  # Ensure labels are float and reshaped correctly\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)  # Accumulate the loss based on the batch size\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        scheduler.step(epoch_loss)\n","\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n","\n","    print(\"Training Complete\")"],"metadata":{"id":"BwHP12GOPODD","executionInfo":{"status":"ok","timestamp":1726212084770,"user_tz":-300,"elapsed":461,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, test_loader, criterion):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","\n","            # Apply sigmoid and threshold to convert logits to binary predictions\n","            predictions = torch.sigmoid(outputs) > 0.5  # Threshold at 0.5\n","            loss = criterion(outputs, labels.unsqueeze(1).float())\n","\n","            total_loss += loss.item() * inputs.size(0)\n","            correct += (predictions.squeeze().long() == labels).sum().item()  # Count correct predictions\n","            total += labels.size(0)\n","\n","    accuracy = 100 * correct / total\n","    avg_loss = total_loss / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%, Test Loss: {avg_loss:.4f}\")\n","\n","    return accuracy, avg_loss"],"metadata":{"id":"ILsguPslPRIB","executionInfo":{"status":"ok","timestamp":1726212085199,"user_tz":-300,"elapsed":5,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","class OptimizedNN(nn.Module):\n","    def __init__(self, input_dim):\n","        super(OptimizedNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.4)\n","        self.bn1 = nn.BatchNorm1d(256)\n","        self.bn2 = nn.BatchNorm1d(128)\n","\n","    def forward(self, x):\n","        x = torch.nn.functional.leaky_relu(self.bn1(self.fc1(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn2(self.fc2(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = self.fc3(x)  # No activation here, as BCEWithLogitsLoss will handle it\n","        return x\n","\n","# Initialize model, criterion, optimizer, and scheduler\n","model = OptimizedNN(input_dim).to(device)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","# Training and evaluation functions remain the same\n","train_model(train_loader, model, criterion, optimizer, scheduler, num_epochs=100)\n","accuracy, avg_loss = evaluate_model(model, test_loader, criterion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSK2Jjl5Og0e","executionInfo":{"status":"ok","timestamp":1726212085985,"user_tz":-300,"elapsed":790,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"18c9d0e1-1de2-46cd-a5ce-5c69eafb6cc3"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 0.633812\n","Epoch 11/100, Loss: 0.164766\n","Epoch 21/100, Loss: 0.078261\n","Epoch 31/100, Loss: 0.027230\n","Epoch 41/100, Loss: 0.021581\n","Epoch 51/100, Loss: 0.039039\n","Epoch 61/100, Loss: 0.086096\n","Epoch 71/100, Loss: 0.015216\n","Epoch 81/100, Loss: 0.022515\n","Epoch 91/100, Loss: 0.027602\n","Training Complete\n","Test Accuracy: 92.86%, Test Loss: 0.3942\n"]}]},{"cell_type":"code","source":["\n","# prompt: show that which question it wrongly predict and what was correct label without embedding column\n","\n","import pandas as pd\n","import torch\n","\n","# Assuming 'df_embed' is your DataFrame and 'test_loader' is your DataLoader\n","\n","def get_wrong_predictions(model, test_loader, df_embed):\n","    \"\"\"\n","    Identifies wrongly predicted instances and returns a DataFrame with the incorrect predictions and true labels.\n","    \"\"\"\n","    model.eval()\n","    wrong_predictions = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            predictions = torch.sigmoid(outputs) > 0.5\n","\n","            for i in range(len(labels)):\n","                if predictions[i].item() != labels[i].item():\n","                    # Get the index of the current instance in the original DataFrame\n","                    index = (len(labels) * test_loader.batch_size) + i\n","                    if index < len(df_embed):  # Ensure index is within bounds\n","                        # Get the related_texts and label from the original DataFrame\n","                        related_texts = df_embed.iloc[index]['related_texts']\n","                        true_label = df_embed.iloc[index]['label']\n","                        predicted_label = predictions[i].item()\n","                        wrong_predictions.append({'related_texts': related_texts, 'true_label': true_label, 'predicted_label': predicted_label})\n","\n","    return pd.DataFrame(wrong_predictions)\n","\n","# Get the DataFrame with wrong predictions\n","wrong_predictions_df = get_wrong_predictions(model, test_loader, df_embed)\n","\n","# Display the results\n"],"metadata":{"id":"gZIFMoS3QnFt","executionInfo":{"status":"ok","timestamp":1726212123071,"user_tz":-300,"elapsed":718,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["wrong_predictions_df"],"metadata":{"id":"l1uqc8aoQrZk","executionInfo":{"status":"ok","timestamp":1726212130770,"user_tz":-300,"elapsed":400,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"2a89bc15-68ab-47c7-9dfe-f3206d118e4a","colab":{"base_uri":"https://localhost:8080/","height":89}},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"],"text/html":["\n","  <div id=\"df-69b6ba4d-611b-433f-bba6-17f61a93bd45\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69b6ba4d-611b-433f-bba6-17f61a93bd45')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-69b6ba4d-611b-433f-bba6-17f61a93bd45 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-69b6ba4d-611b-433f-bba6-17f61a93bd45');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_aa68011f-b0ae-4c71-80d2-8ce95334e0e2\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('wrong_predictions_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_aa68011f-b0ae-4c71-80d2-8ce95334e0e2 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('wrong_predictions_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"wrong_predictions_df","summary":"{\n  \"name\": \"wrong_predictions_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"}},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"-8-8_wn2OhBg"}},{"cell_type":"code","source":["# prompt: show that which question it wrongly predict and what was correct label without embedding column\n","\n","import pandas as pd\n","import torch\n","\n","# Assuming 'df_embed' is your DataFrame and 'test_loader' is your DataLoader\n","\n","def get_wrong_predictions(model, test_loader, df_embed):\n","    \"\"\"\n","    Identifies wrongly predicted instances and returns a DataFrame with the incorrect predictions and true labels.\n","    \"\"\"\n","    model.eval()\n","    wrong_predictions = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            predictions = torch.sigmoid(outputs) > 0.5\n","\n","            for i in range(len(labels)):\n","                if predictions[i].item() != labels[i].item():\n","                    # Get the index of the current instance in the original DataFrame\n","                    index = (len(labels) * test_loader.batch_size) + i\n","                    if index < len(df_embed):  # Ensure index is within bounds\n","                        # Get the related_texts and label from the original DataFrame\n","                        related_texts = df_embed.iloc[index]['related_texts']\n","                        true_label = df_embed.iloc[index]['label']\n","                        predicted_label = predictions[i].item()\n","                        wrong_predictions.append({'related_texts': related_texts, 'true_label': true_label, 'predicted_label': predicted_label})\n","\n","    return pd.DataFrame(wrong_predictions)\n","\n","# Get the DataFrame with wrong predictions\n","wrong_predictions_df = get_wrong_predictions(model, test_loader, df_embed)\n","\n","# Display the results\n"],"metadata":{"id":"0acfUXrnP8Ml","executionInfo":{"status":"ok","timestamp":1726212091122,"user_tz":-300,"elapsed":442,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["wrong_predictions_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"Y80XHu9hQM0C","executionInfo":{"status":"ok","timestamp":1726212093403,"user_tz":-300,"elapsed":430,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"7d049103-ca85-45c8-af48-8a6c9f7bea69"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"],"text/html":["\n","  <div id=\"df-9755b271-d984-4332-9840-3d5d6da93b15\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9755b271-d984-4332-9840-3d5d6da93b15')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9755b271-d984-4332-9840-3d5d6da93b15 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9755b271-d984-4332-9840-3d5d6da93b15');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_c7d0dfef-9152-4cab-8771-3efb7dcd0276\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('wrong_predictions_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_c7d0dfef-9152-4cab-8771-3efb7dcd0276 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('wrong_predictions_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"wrong_predictions_df","summary":"{\n  \"name\": \"wrong_predictions_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"}},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["def evaluate_model(model, test_loader, criterion, df):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    total_loss = 0.0\n","    incorrect_predictions = []\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(test_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            # Ensure labels are float and have shape [batch_size, 1]\n","            labels = labels.unsqueeze(1).float()\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    avg_loss = total_loss / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%, Test Loss: {avg_loss:.4f}\")\n","\n","    return accuracy, avg_loss, incorrect_predictions"],"metadata":{"id":"R39VjOZcw3Ny","executionInfo":{"status":"ok","timestamp":1726210994165,"user_tz":-300,"elapsed":375,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["class AdvancedNNSecond(nn.Module):\n","    def __init__(self, input_dim):\n","        super(AdvancedNNSecond, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)  # Increased neurons\n","        self.fc2 = nn.Linear(128, 256)\n","        self.fc3 = nn.Linear(256, 512)\n","        self.fc4 = nn.Linear(512, 256)\n","        self.fc5 = nn.Linear(256, 128)\n","        self.fc6 = nn.Linear(128, 1) # This layer outputs a single value\n","        self.dropout = nn.Dropout(0.4)  # Adjusted dropout rate\n","        self.bn1 = nn.BatchNorm1d(128)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.bn3 = nn.BatchNorm1d(512)\n","        self.bn4 = nn.BatchNorm1d(256)\n","        self.bn5 = nn.BatchNorm1d(128)\n","\n","    def forward(self, x):\n","        x = torch.nn.functional.leaky_relu(self.bn1(self.fc1(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn2(self.fc2(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn3(self.fc3(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn4(self.fc4(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn5(self.fc5(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = self.fc6(x) # Remove sigmoid activation. BCEWithLogitsLoss applies sigmoid internally\n","        return x"],"metadata":{"id":"lXK9usHMKgrC","executionInfo":{"status":"ok","timestamp":1726210995067,"user_tz":-300,"elapsed":3,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["model = AdvancedNNSecond(input_dim).to(device)\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"],"metadata":{"id":"_U16Q_TsKlyE","executionInfo":{"status":"ok","timestamp":1726210996481,"user_tz":-300,"elapsed":1,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n","accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df_embed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UeNPFbDKrty","executionInfo":{"status":"ok","timestamp":1726211003864,"user_tz":-300,"elapsed":6870,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}},"outputId":"71325330-bab4-4267-bed0-19d8beb71f40"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 0.489243\n","Epoch 11/100, Loss: 0.128841\n","Epoch 21/100, Loss: 0.094373\n","Epoch 31/100, Loss: 0.091612\n","Epoch 41/100, Loss: 0.047859\n","Epoch 51/100, Loss: 0.063846\n","Epoch 61/100, Loss: 0.041919\n","Epoch 71/100, Loss: 0.047985\n","Epoch 81/100, Loss: 0.031439\n","Epoch 91/100, Loss: 0.032553\n","Training Complete\n","Test Accuracy: 2823.60%, Test Loss: 0.0471\n"]}]},{"cell_type":"code","source":["# prompt: why Test Accuracy: 2823.60%,\n","\n","# The issue likely stems from a mismatch between your model's output and the expected labels.\n","# BCEWithLogitsLoss applies sigmoid internally, so you don't need to apply sigmoid in your model's forward pass.\n","# Additionally, ensure that your labels are in the correct format (e.g., float values).\n","# Check if your labels are in the correct format.\n","# Review the model's architecture and ensure it's suitable for the binary classification task.\n","# Consider adding more layers or adjusting the number of neurons in your model.\n","# Try different activation functions.\n","# Experiment with different optimizers and learning rates.\n","# Adjust the batch size and number of epochs.\n"],"metadata":{"id":"oHru7O5BMg3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AdvancedNNSecond(nn.Module):\n","    def __init__(self, input_dim):\n","        super(AdvancedNNSecond, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)  # Increased neurons\n","        self.fc2 = nn.Linear(128, 256)\n","        self.fc3 = nn.Linear(256, 512)\n","        self.fc4 = nn.Linear(512, 256)\n","        self.fc5 = nn.Linear(256, 128)\n","        self.fc6 = nn.Linear(128, 1) # This layer outputs a single value\n","        self.dropout = nn.Dropout(0.4)  # Adjusted dropout rate\n","        self.bn1 = nn.BatchNorm1d(128)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.bn3 = nn.BatchNorm1d(512)\n","        self.bn4 = nn.BatchNorm1d(256)\n","        self.bn5 = nn.BatchNorm1d(128)\n","\n","    def forward(self, x):\n","        x = torch.nn.functional.leaky_relu(self.bn1(self.fc1(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn2(self.fc2(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn3(self.fc3(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn4(self.fc4(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = torch.nn.functional.leaky_relu(self.bn5(self.fc5(x)), negative_slope=0.01)\n","        x = self.dropout(x)\n","        x = self.fc6(x) # Remove sigmoid activation. BCEWithLogitsLoss applies sigmoid internally\n","        return x"],"metadata":{"id":"jKAwOddCw67Z","executionInfo":{"status":"ok","timestamp":1726210683464,"user_tz":-300,"elapsed":371,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# prompt: make MulticlassModel1 binary classification\n","\n","class BinaryMulticlassModel1(nn.Module):\n","    def __init__(self, input_size):\n","        super(BinaryMulticlassModel1, self).__init__()\n","        self.layer1 = nn.Linear(input_size, 512)\n","        self.layer2 = nn.Linear(512, 1024)\n","        self.layer3 = nn.Linear(1024, 512)\n","        self.output = nn.Linear(512, 1)  # Output layer for binary classification\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.batch_norm1 = nn.BatchNorm1d(512)\n","        self.batch_norm2 = nn.BatchNorm1d(1024)\n","        self.sigmoid = nn.Sigmoid()  # Add sigmoid activation for binary output\n","\n","    def forward(self, x):\n","        x = self.relu(self.batch_norm1(self.layer1(x)))\n","        x = self.dropout(x)\n","        x = self.relu(self.batch_norm2(self.layer2(x)))\n","        x = self.dropout(x)\n","        x = self.relu(self.layer3(x))\n","        x = self.dropout(x)\n","        x = self.output(x)\n","        x = self.sigmoid(x)  # Apply sigmoid activation\n","        return x\n"],"metadata":{"id":"H1feGlivKPNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim"],"metadata":{"id":"wxRvB-gq2QMd","executionInfo":{"status":"ok","timestamp":1726210543949,"user_tz":-300,"elapsed":4,"user":{"displayName":"Dovud Asadov","userId":"00818708860879583898"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["model = MulticlassModel1(input_size=input_dim, num_classes=num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"],"metadata":{"id":"UYIXY4-nw8vR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n","accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df_embed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GUtNO0Zw-QB","outputId":"d035274f-b1ce-43cd-a5d9-d129c8371005"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 1.905589\n","Epoch 11/100, Loss: 1.494001\n","Epoch 21/100, Loss: 1.408900\n","Epoch 31/100, Loss: 1.346037\n","Epoch 41/100, Loss: 1.305883\n","Epoch 51/100, Loss: 1.269428\n","Epoch 61/100, Loss: 1.239488\n","Epoch 71/100, Loss: 1.215465\n","Epoch 81/100, Loss: 1.197714\n","Epoch 91/100, Loss: 1.174214\n","Training Complete\n","Test Accuracy: 50.50%, Test Loss: 1.4939\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Lexuz Project/Model/Roberta_Uzbek_model/model1.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4R0I6Zvi3DFA","outputId":"a8ea76fd-da08-43e0-d8a9-5743f988e65f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["class MulticlassModel2(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(MulticlassModel2, self).__init__()\n","        self.layer1 = nn.Linear(input_size, 512)\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.layer2 = nn.Linear(512, 1024)\n","        self.bn2 = nn.BatchNorm1d(1024)\n","        self.layer3 = nn.Linear(1024, 2048)\n","        self.bn3 = nn.BatchNorm1d(2048)\n","        self.layer4 = nn.Linear(2048, 1024)\n","        self.bn4 = nn.BatchNorm1d(1024)\n","        self.layer5 = nn.Linear(1024, 512)\n","        self.bn5 = nn.BatchNorm1d(512)\n","        self.output = nn.Linear(512, num_classes)\n","\n","        self.elu = nn.ELU()\n","        self.dropout1 = nn.Dropout(p=0.3)\n","        self.dropout2 = nn.Dropout(p=0.4)\n","\n","    def forward(self, x):\n","        x = self.elu(self.bn1(self.layer1(x)))\n","        x = self.dropout1(x)\n","        x = self.elu(self.bn2(self.layer2(x)))\n","        x = self.dropout2(x)\n","        x = self.elu(self.bn3(self.layer3(x)))\n","        x = self.dropout2(x)\n","        x = self.elu(self.bn4(self.layer4(x)))\n","        x = self.dropout2(x)\n","        x = self.elu(self.bn5(self.layer5(x)))\n","        x = self.dropout1(x)\n","        x = self.output(x)\n","        return x"],"metadata":{"id":"A6hEocyOyNAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MulticlassModel2(input_size=input_dim, num_classes=num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"metadata":{"id":"gfCHxd0lyPJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n","accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df_embed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKTFuj8AyRVj","outputId":"4c9619a8-af51-4bba-cb9d-a36c7c85adfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 1.870201\n","Epoch 11/100, Loss: 1.474535\n","Epoch 21/100, Loss: 1.371375\n","Epoch 31/100, Loss: 1.299886\n","Epoch 41/100, Loss: 1.239641\n","Epoch 51/100, Loss: 1.186262\n","Epoch 61/100, Loss: 1.144104\n","Epoch 71/100, Loss: 1.107287\n","Epoch 81/100, Loss: 1.074353\n","Epoch 91/100, Loss: 1.041186\n","Training Complete\n","Test Accuracy: 47.98%, Test Loss: 1.5971\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Lexuz Project/Model/Roberta_Uzbek_model/model2.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrfIyPKr6NZV","outputId":"59d11c25-3ef6-4c8f-fba2-7fb0f0d4c753"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["class MulticlassModel3(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(MulticlassModel3, self).__init__()\n","        self.layer1 = nn.Linear(input_size, 512)\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.layer2 = nn.Linear(512, 1024)\n","        self.bn2 = nn.BatchNorm1d(1024)\n","        self.layer3 = nn.Linear(1024, 2048)\n","        self.bn3 = nn.BatchNorm1d(2048)\n","        self.layer4 = nn.Linear(2048, 1024)\n","        self.bn4 = nn.BatchNorm1d(1024)\n","        self.layer5 = nn.Linear(1024, 512)\n","        self.bn5 = nn.BatchNorm1d(512)\n","        self.output = nn.Linear(512, num_classes)\n","\n","        self.relu = nn.ReLU()\n","        self.dropout1 = nn.Dropout(p=0.3)\n","        self.dropout2 = nn.Dropout(p=0.4)\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.layer1(x)))\n","        x = self.dropout1(x)\n","        x = self.relu(self.bn2(self.layer2(x)))\n","        x = self.dropout2(x)\n","        x = self.relu(self.bn3(self.layer3(x)))\n","        x = self.dropout2(x)\n","        x = self.relu(self.bn4(self.layer4(x)))\n","        x = self.dropout2(x)\n","        x = self.relu(self.bn5(self.layer5(x)))\n","        x = self.dropout1(x)\n","        x = self.output(x)\n","        return x"],"metadata":{"id":"l8WSjw1tyUKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MulticlassModel3(input_size=input_dim, num_classes=num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"],"metadata":{"id":"WlynizfjyWJN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n","accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df_embed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtGFDgJyyYAb","outputId":"82b5e7d6-8f99-4645-fc07-4915db8eb60b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 1.917979\n","Epoch 11/100, Loss: 1.471885\n","Epoch 21/100, Loss: 1.393305\n","Epoch 31/100, Loss: 1.345253\n","Epoch 41/100, Loss: 1.311792\n","Epoch 51/100, Loss: 1.289091\n","Epoch 61/100, Loss: 1.268927\n","Epoch 71/100, Loss: 1.252443\n","Epoch 81/100, Loss: 1.240743\n","Epoch 91/100, Loss: 1.226028\n","Training Complete\n","Test Accuracy: 49.19%, Test Loss: 1.5185\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Lexuz Project/Model/Roberta_Uzbek_model/model3.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbLRxXGI6UdC","outputId":"f486acb5-a1fe-49fe-9557-eebb4743f434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#@title Enter Text\n","text = \"O‘zbekiston Respublikasi Vazirlar Mahkamasi: davlat hisobidan yuridik yordam ko‘rsatish sohasida yagona davlat siyosati amalga oshirilishini ta’minlaydi; davlat hisobidan yuridik yordam ko‘rsatish sohasidagi davlat dasturlarini tasdiqlaydi va ularning amalga oshirilishini ta’minlaydi; advokatlar tomonidan davlat hisobidan ko‘rsatilgan yuridik yordam uchun haq to‘lash miqdori va tartibini belgilaydi; davlat hisobidan yuridik yordam ko‘rsatish sohasidagi normativ-huquqiy hujjatlarni o‘z vakolatlari doirasida qabul qiladi.\" #@param {type:\"string\"}\n"],"metadata":{"id":"ToFVrK1yxAyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import re\n","import torch.nn.functional as F\n","\n","def predict_class(text, model, tokenizer, label_to_numeric, device):\n","    \"\"\"\n","    Predicts the class of the given text using the trained model.\n","\n","    Args:\n","        text: The input text.\n","        model: The trained model.\n","        tokenizer: The tokenizer used for the model.\n","        label_to_numeric: A dictionary mapping labels to numeric values.\n","        device: The device to use for computation (CPU or GPU).\n","\n","    Returns:\n","        A list of top 3 predicted classes with their probabilities.\n","    \"\"\"\n","\n","    cleaned_text = text.lower()\n","    cleaned_text = cleaned_text.replace('‘', \"'\").replace('’', \"'\").replace('`', \"'\")\n","    cleaned_text = re.sub(r'[^a-z\\.\\'\\s]', '', cleaned_text)\n","    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n","\n","    inputs = tokenizer(cleaned_text, return_tensors='pt', truncation=True, padding=True, max_length=256)\n","\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model_embedding(**inputs)\n","        embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n","\n","    with torch.no_grad():\n","        model.eval()\n","        logits = model(embeddings)\n","        probabilities = F.softmax(logits, dim=1)\n","\n","    top3_probs, top3_indices = torch.topk(probabilities, 3)\n","\n","    numeric_to_label = {v: k for k, v in label_to_numeric.items()}\n","    top3_predictions = [(numeric_to_label[idx.item()], prob.item()) for idx, prob in zip(top3_indices[0], top3_probs[0])]\n","\n","    return top3_predictions\n","\n","predictions = predict_class(text, model, tokenizer, label_to_numeric, device)\n","\n","print(\"Top 3 Predictions:\")\n","for label, prob in predictions:\n","    print(f\"Class: {label}, Probability: {prob:.4f}\")"],"metadata":{"id":"suy4wohTxHdU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Word2Vec Embedding**"],"metadata":{"id":"Un8XEiLXxSlP"}},{"cell_type":"code","source":["processed_docs = df_new['related_texts'].tolist()"],"metadata":{"id":"yYQzcq42xVjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flattened_docs = [word for word in processed_docs]"],"metadata":{"id":"eWx6CSAFyhjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = [doc.split() for doc in flattened_docs]"],"metadata":{"id":"awok0_yNJdb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_word2vec = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1, workers=multiprocessing.cpu_count())\n","\n","if '<OOV>' not in model_word2vec.wv:\n","    model_word2vec.wv.add_vector('<OOV>', np.zeros(model_word2vec.vector_size))\n","\n","model_word2vec.save(\"word2vec_uzbek.model\")\n","\n","model_word2vec = Word2Vec.load(\"word2vec_uzbek.model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xP5o14_Xylpk","outputId":"5f6a3a14-c301-4e52-eb49-26ac28f892c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# prompt: free ram and gpu\n","\n","import torch\n","\n","# Clear GPU cache\n","torch.cuda.empty_cache()\n","\n","# Garbage collection\n","import gc\n","gc.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNRbQkaCMR4S","outputId":"abcee164-f635-43b3-815e-222daf611a51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["531"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["!cp \"/content/word2vec_uzbek.model\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec\""],"metadata":{"id":"X5m05nirMDKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_word2vec = Word2Vec.load(\"word2vec_uzbek.model\")\n","\n","def preprocess_data(df, model):\n","\n","    def get_embedding(text, model, oov_token='<OOV>'):\n","        tokens = text.split()\n","        embeddings = []\n","        for token in tokens:\n","            if token in model.wv:\n","                embeddings.append(model.wv[token])\n","            else:\n","                embeddings.append(model.wv[oov_token])\n","        if embeddings:\n","            return np.mean(embeddings, axis=0)\n","        else:\n","            return np.zeros(model.vector_size)\n","\n","    # Apply the custom Word2Vec model to get embeddings\n","    df.loc[:, 'embeddings'] = df['related_texts'].apply(lambda text: get_embedding(text, model))\n","\n","    return df"],"metadata":{"id":"h8r_4N6syncD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_word_2_vec = preprocess_data(df_new, model_word2vec)"],"metadata":{"id":"08JCHd7fyol1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_to_numeric = {label: idx for idx, label in enumerate(df_word_2_vec['okoz_text'].unique())}\n","df_word_2_vec['label'] = df_word_2_vec['okoz_text'].map(label_to_numeric)"],"metadata":{"id":"Ei_tukyCNoJT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_df = pd.DataFrame(list(label_to_numeric.items()), columns=['okoz_text', 'label'])\n","\n","label_df.to_csv('label_to_numerics.csv', index=False)\n","\n","!cp \"/content/label_to_numeric.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQ8u-0kpOAH5","outputId":"581ba516-f354-4d2d-942d-e2ad69753dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/label_to_numeric.csv': No such file or directory\n"]}]},{"cell_type":"code","source":["!cp \"/content/label_to_numerics.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec\""],"metadata":{"id":"ft2QJNizVavQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_word_2_vec.drop(columns=[\"okoz_text\"],inplace=True)"],"metadata":{"id":"O5XHRNuFNvuQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_word_2_vec.to_csv('word2vec_embedded_with_text.csv', index=False)\n","df_word_2_vec.to_json('word2vec_embedded_with_texts.json', index=False)"],"metadata":{"id":"ANeYKza8Oekp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/word2vec_embedded_with_text.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec/Embedded Data\"\n","!cp \"/content/word2vec_embedded_with_texts.json\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec/Embedded Data\""],"metadata":{"id":"jRCUmLWqOrNg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_word_2_vec = df_word_2_vec[['embeddings', 'label']]"],"metadata":{"id":"euJALK4QOdz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_word_2_vec.to_csv('word2vec_embedded.csv', index=False)\n","df_word_2_vec.to_json('word2vec_embedding.json', index=False)"],"metadata":{"id":"MtLZmMvOOdOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/word2vec_embedded.csv\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec/Embedded Data\"\n","!cp \"/content/word2vec_embedding.json\" \"/content/drive/MyDrive/Lexuz Project/Embeddings/Word2Vec/Embedded Data\""],"metadata":{"id":"4dS19ZdhQTkp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prep_model(df, batch_size):\n","    X = np.array(df['embeddings'].tolist())\n","    y = np.array(df['label'])\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n","    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader"],"metadata":{"id":"Lu8yba3CRa9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader, test_loader = prep_model(df_word_2_vec, 32)"],"metadata":{"id":"MJSCsCiIRaWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_classes = df_word_2_vec['label'].nunique()\n","input_dim = np.array(df_word_2_vec['embeddings'][0]).shape[0]"],"metadata":{"id":"qUcdzryjRZz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(train_loader, model, criterion, optimizer, scheduler, num_epochs=100):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * inputs.size(0)\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        scheduler.step(epoch_loss)\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n","\n","    print(\"Training Complete\")"],"metadata":{"id":"34Aj3Vh9Rs4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, test_loader, criterion, df):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    total_loss = 0.0\n","    incorrect_predictions = []\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(test_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    avg_loss = total_loss / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%, Test Loss: {avg_loss:.4f}\")\n","\n","    return accuracy, avg_loss, incorrect_predictions"],"metadata":{"id":"WsOx29saRsKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MulticlassModel1(nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(MulticlassModel1, self).__init__()\n","        self.layer1 = nn.Linear(input_size, 512)\n","        self.layer2 = nn.Linear(512, 1024)\n","        self.layer3 = nn.Linear(1024, 512)\n","        self.output = nn.Linear(512, num_classes)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.batch_norm1 = nn.BatchNorm1d(512)\n","        self.batch_norm2 = nn.BatchNorm1d(1024)\n","\n","    def forward(self, x):\n","        x = self.relu(self.batch_norm1(self.layer1(x)))\n","        x = self.dropout(x)\n","        x = self.relu(self.batch_norm2(self.layer2(x)))\n","        x = self.dropout(x)\n","        x = self.relu(self.layer3(x))\n","        x = self.dropout(x)\n","        x = self.output(x)\n","        return x"],"metadata":{"id":"95YXcjt9RrV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MulticlassModel1(input_size=input_dim, num_classes=num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"],"metadata":{"id":"1EpXtzYqRqfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(train_loader, model, criterion, optimizer,scheduler, num_epochs=100)\n","accuracy, avg_loss, incorrect_predictions = evaluate_model(model, test_loader, criterion, df_word_2_vec)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KVuGBpbRh0n","outputId":"252a8983-a4d7-4ed2-ec66-4cf15a01b93e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 1.912522\n","Epoch 11/100, Loss: 1.540153\n","Epoch 21/100, Loss: 1.454182\n","Epoch 31/100, Loss: 1.403857\n","Epoch 41/100, Loss: 1.368512\n","Epoch 51/100, Loss: 1.338873\n","Epoch 61/100, Loss: 1.320523\n","Epoch 71/100, Loss: 1.301454\n","Epoch 81/100, Loss: 1.225904\n","Epoch 91/100, Loss: 1.207040\n","Training Complete\n","Test Accuracy: 50.48%, Test Loss: 1.5216\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Lexuz Project/Model/Word2Vec_model/model1.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaAtsvcYS_nq","outputId":"f0621e6e-adcb-4cdc-ab5d-9cf1d1b822fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]}]}